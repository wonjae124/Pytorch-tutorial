{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "torch.autograd_tutorial",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNj8f09lfgK0EBW5jLWB6sq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wonjae124/Pytorch-tutorial/blob/main/torch_autograd_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "b0yyekfMp_xn"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1,1000)"
      ],
      "metadata": {
        "id": "a8eRB9vLqLxe"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(data)"
      ],
      "metadata": {
        "id": "xts5hfEpqMWl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt4rpBuLq8aG",
        "outputId": "9ad27372-ca6e-4549-b203-d5c81b544eed"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = (prediction-labels).sum()\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "ZhTz52oiqQl0"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9)"
      ],
      "metadata": {
        "id": "GAmobhsQqT6o"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optim.step()"
      ],
      "metadata": {
        "id": "Ue6VvtgxqZyL"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd에서 미분"
      ],
      "metadata": {
        "id": "7MjVmblStI3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2.,3.], requires_grad=True)\n",
        "b = torch.tensor([6.,4.],requires_grad=True)"
      ],
      "metadata": {
        "id": "Q4k7HO8kqze8"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "metadata": {
        "id": "c8ysdNHhtTmL"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5COCMMZt9B8",
        "outputId": "ee61354b-3fa5-4a52-f1b7-7f9c32f638e3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad) "
      ],
      "metadata": {
        "id": "wOf7K9QDtYgl"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt1-efeDtyQG",
        "outputId": "b5b6ac89-790c-45a8-eb29-3eefb94ce096"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# directed acycli graph에서 제외하기"
      ],
      "metadata": {
        "id": "cQ5S79dUvnyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad = True)\n",
        "\n",
        "a = x+y\n",
        "print(f\"Does 'a' requires gradienets? :{a.requires_grad}\")\n",
        "\n",
        "b = x+z\n",
        "print(f\"Does 'b' require gradients? : {b.requires_grad}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvX3M1z-vyIf",
        "outputId": "5f7ab2d4-5183-43b5-969d-9af8cf152fb6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Does 'a' requires gradienets? :False\n",
            "Does 'b' require gradients? : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 변화도를 계산하지 않는 매개변수를 고정시키기. Frozen parameter\n",
        "# Fine Tuning"
      ],
      "metadata": {
        "id": "czMC0dsuwTqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "l6VoK03dwYhk"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc = nn.Linear(512, 10)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9) "
      ],
      "metadata": {
        "id": "ju9RqihuwrBz"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saved tensor"
      ],
      "metadata": {
        "id": "dZdZLAiw0IGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(5, requires_grad = True)\n",
        "y = x.pow(2)\n",
        "print(x.equal(y.grad_fn._saved_self))\n",
        "print(x is y.grad_fn._saved_self)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ1wEcEu0J57",
        "outputId": "4ef960d4-a59d-4cc4-b404-34d7475da2fa"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjG4SzhK0cQm",
        "outputId": "a519d2a1-e950-491c-a214-5717caf7e609"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 1.0902, -0.5721,  0.1925,  0.3065, -0.9836], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6oHUg500j3M",
        "outputId": "9657a09e-11ee-4fa0-8ed4-6b7961a6fb03"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.1886, 0.3272, 0.0371, 0.0939, 0.9675], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.grad_fn._saved_self"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aghpf97g0qWZ",
        "outputId": "86e05025-7665-4a92-f121-357eb7e21d09"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0902, -0.5721,  0.1925,  0.3065, -0.9836], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5, requires_grad = True)\n",
        "y = x.exp()\n",
        "print(y.equal(y.grad_fn._saved_result)) # 같은 차원과 element를 가지고 있을 때 torch.equal()사용\n",
        "print(y is y.grad_fn._saved_result) #같은 객체인지를 볼 때 is 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hT3cmDC1DJ3",
        "outputId": "e626bf2b-037a-40e2-dd85-68ece3890bd9"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D_BEpjcI4EG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y == y.grad_fn._saved_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAZ7ghv74ENo",
        "outputId": "cdabbc54-2a1c-4da4-eefa-59eb142758a6"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqFeZubz2Ng3",
        "outputId": "d485ec84-8da7-47c4-a591-4f799eddf802"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0957, 2.3128, 1.1693, 1.4164, 1.8381], grad_fn=<ExpBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn._saved_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxAsvETR2PFh",
        "outputId": "adfccd21-b26b-4e7d-97c2-6d60a994c95c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.0957, 2.3128, 1.1693, 1.4164, 1.8381], grad_fn=<ExpBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multithreaded Autograd"
      ],
      "metadata": {
        "id": "egWB2rgtzGMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fn():\n",
        "  x = torch.ones(5, 5, requires_grad = True)\n",
        "  y = (x+3)*(x+4)*0.5\n",
        "\n",
        "  y.sum().backward()\n",
        "\n",
        "threads = []\n",
        "\n",
        "for _ in range(10):\n",
        "  p = threading.Thread(target = train_fn, args = ())\n",
        "  p.start()\n",
        "  threads.append(p)\n",
        "\n",
        "for p in threads:\n",
        "  p.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "FyYZNFbBzFc-",
        "outputId": "8917657a-f1bc-49dd-ad9e-af550eee2ced"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-db6f47f53a18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'threading' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ow-OAwIx4cXy"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q6Z764s0w1qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autograd & Variable\n",
        "# https://do-hansung.tistory.com/16\n"
      ],
      "metadata": {
        "id": "ZzPt7vBt4c0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "a = torch.ones(2,2)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHfY5TB-4gla",
        "outputId": "182bdf0a-36e6-469e-bf7a-7a2dc68d9ad9"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = Variable(a, requires_grad=True)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpDspWUI4yJh",
        "outputId": "b19602cd-2bad-449a-ad8b-bdd7522d0224"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du4atZpt5Tb3",
        "outputId": "1cc9c9d0-7208-4216-979b-b4d09f4a7d08"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEXle3AO5XJm",
        "outputId": "9186435c-8a71-4ac2-dba6-9d1da3d91668"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idJ33ZiT5Ylr",
        "outputId": "3576a687-5ae9-45d7-84f9-204cc4a488bb"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a + 2\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEijyYRC42Xl",
        "outputId": "cf1e836e-4c85-4999-d48c-95bee4ae5f40"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = b**2\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkNb7JTv45g4",
        "outputId": "dac67f2e-bbd4-4372-c147-bf60d93d99a0"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = c.sum()\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVOedx-247d4",
        "outputId": "0bb08f49-6919-49e5-9e21-dda2c26e7cb9"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.backward() #backward 함수가 grad를 채워준다.\n",
        "print(a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Auh0lQb94-Ow",
        "outputId": "41287738-45f5-4899-9dc6-30404b47f053"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 6.],\n",
            "        [6., 6.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad_fn) #a가 직접 수행한 연산이 없기 때문에 None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvaCPFNa_G2b",
        "outputId": "6c509a77-dfeb-4a21-f1c4-1762ebd9dbc4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsFem7Pp_TkB",
        "outputId": "01e5f44d-d1d0-49a1-8872-372b61b29cb3"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3., 3.],\n",
              "        [3., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq9w0wzq_bJF",
        "outputId": "35f0768b-c419-4db1-b6e0-9fbf24738827"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b.grad_fn) #b는 이전에 b = a+2로 기울기가 있는 연산(AddBackward)를 한 상태임"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oI13FL-_gFK",
        "outputId": "1c77877e-6313-43f5-9913-418554b6c3e9"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7f00628f6850>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM6LKmvl_i-y",
        "outputId": "1f9d608e-ec64-4e39-8c83-ee12535cf8ae"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9., 9.],\n",
            "        [9., 9.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_8gOHUfAK0D",
        "outputId": "32b3a52c-ed4f-42d5-fa08-8c1df17dd625"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e76SiQ6wALhk",
        "outputId": "cc2b0a0c-5470-4918-b605-b10a538d46ec"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PowBackward0 object at 0x7f0062950990>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcMBPOyGAMkr",
        "outputId": "ee55764e-e1fe-48a1-bd5e-900a9beade38"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(36.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCpmA7LEAQMi",
        "outputId": "b83854a9-0661-423d-943c-2f4dc283539e"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1013: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:417.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWtYCMa1AQ4q",
        "outputId": "61833a22-a01b-4238-909b-33916c7ddd28"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SumBackward0 object at 0x7f0063732f90>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(3)\n",
        "x = Variable(x, requires_grad = True)\n",
        "y = x**2\n",
        "z = y*3\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5T2mrVdASNp",
        "outputId": "1f99a1ec-373a-419e-bf65-0832927a2671"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 3., 3.], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grad = torch.Tensor([0.1, 1, 10])\n",
        "z.backward(grad) #z=3x^2을 x에 대해 편미분 하면 6x가 된다. 이는 결국 x를 업데이트 하기 위함을 뜻 한다."
      ],
      "metadata": {
        "id": "TOa8_oY-AuRc"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iULWgDwBAyDC",
        "outputId": "11be56e8-50ce-43ce-fa13-b5ecaaac21ee"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad) # 이전의 gradient 값에 차례로 6을 곱한다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkP7O2xTA0o6",
        "outputId": "72d61eac-6df8-4f78-ef08-41a5c8ea1bcf"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.6000,  6.0000, 60.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNMR7UPrA1kf",
        "outputId": "8c382883-de2a-4857-8bfc-49777b68c119"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exYX6-ogA2m5",
        "outputId": "6d2657a2-55f6-432b-c346-de2511a415a9"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function print>"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X8Trxc-oE2td"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}